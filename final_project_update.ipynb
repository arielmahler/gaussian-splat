{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the sift algorithm, with the trilinear interpolation smoothing of a histogram tensor of the generate descriptors being implemented in hardware using our overlay, histogram_tensor\n",
    "\n",
    "This overlay streams in inputs for the histogram tensor calculations, which are done on the board, and the resulting structure is stream back out and placed back into the software structure for further calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\ntry {\nrequire(['notebook/js/codecell'], function(codecell) {\n  codecell.CodeCell.options_default.highlight_modes[\n      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n      Jupyter.notebook.get_cells().map(function(cell){\n          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n  });\n});\n} catch (e) {};\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq import Overlay\n",
    "overlay = Overlay('/home/xilinx/pynq/overlays/descriptor/design_1.bit')\n",
    "dma = overlay.axi_dma_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to find keypoints and descriptors for the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfm_algo_unpacked import generateBaseImage, computeNumberOfOctaves, generateGaussianKernels, generateGaussianImages, generateDoGImages, findScaleSpaceExtrema, removeDuplicateKeypoints, convertKeypointsToInputImageSize, generateDescriptors, generateDescriptors_hardware\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "img1 = cv2.imread('dino_data/dino02.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "sigma=1.6 \n",
    "num_intervals=3 \n",
    "assumed_blur=0.5 \n",
    "image_border_width=5\n",
    "\n",
    "base_image = generateBaseImage(img1, sigma, assumed_blur)\n",
    "print(\"Finished base_image\")\n",
    "num_octaves = computeNumberOfOctaves(base_image.shape)\n",
    "print(\"Finished num_octaves\")\n",
    "gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "print(\"Finished gaussian_kernels\")\n",
    "gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "print(\"Finished gaussian_images\")\n",
    "dog_images = generateDoGImages(gaussian_images)\n",
    "print(\"Finished dog_images\")\n",
    "keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "print(\"Finished keypoints\")\n",
    "keypoints = removeDuplicateKeypoints(keypoints)\n",
    "print(\"Finished remove duplicate keypoints\")\n",
    "kp1 = convertKeypointsToInputImageSize(keypoints)\n",
    "print(\"Finished convert to image size\")\n",
    "des1 = generateDescriptors_hardware(keypoints, gaussian_images, dma)\n",
    "print(\"Finished generate_descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to find keypoints and descriptors for the second image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfm_algo_unpacked import generateBaseImage, computeNumberOfOctaves, generateGaussianKernels, generateGaussianImages, generateDoGImages, findScaleSpaceExtrema, removeDuplicateKeypoints, convertKeypointsToInputImageSize, generateDescriptors, generateDescriptors_hardware\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "img2 = cv2.imread('dino_data/dino05.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "sigma=1.6 \n",
    "num_intervals=3 \n",
    "assumed_blur=0.5 \n",
    "image_border_width=5\n",
    "\n",
    "base_image = generateBaseImage(img1, sigma, assumed_blur)\n",
    "print(\"Finished base_image\")\n",
    "num_octaves = computeNumberOfOctaves(base_image.shape)\n",
    "print(\"Finished num_octaves\")\n",
    "gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "print(\"Finished gaussian_kernels\")\n",
    "gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "print(\"Finished gaussian_images\")\n",
    "dog_images = generateDoGImages(gaussian_images)\n",
    "print(\"Finished dog_images\")\n",
    "keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "print(\"Finished keypoints\")\n",
    "keypoints = removeDuplicateKeypoints(keypoints)\n",
    "print(\"Finished remove duplicate keypoints\")\n",
    "kp2 = convertKeypointsToInputImageSize(keypoints)\n",
    "print(\"Finished convert to image size\")\n",
    "des2 = generateDescriptors_hardware(keypoints, gaussian_images, dma)\n",
    "print(\"Finished generate_descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to run to show the found keypoints and match them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Lowe's ratio test\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "\n",
    "# Estimate homography between template and scene\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "M = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)[0]\n",
    "\n",
    "# Draw detected template in scene image\n",
    "h, w = img1.shape\n",
    "pts = np.float32([[0, 0],\n",
    "                    [0, h - 1],\n",
    "                    [w - 1, h - 1],\n",
    "                    [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "dst = cv2.perspectiveTransform(pts, M)\n",
    "\n",
    "img2 = cv2.polylines(img2, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "\n",
    "h1, w1 = img1.shape\n",
    "h2, w2 = img2.shape\n",
    "nWidth = w1 + w2\n",
    "nHeight = max(h1, h2)\n",
    "hdif = int((h2 - h1) / 2)\n",
    "newimg = np.zeros((nHeight, nWidth, 3), np.uint8)\n",
    "\n",
    "for i in range(3):\n",
    "    newimg[hdif:hdif + h1, :w1, i] = img1\n",
    "    newimg[:h2, w1:w1 + w2, i] = img2\n",
    "\n",
    "# Draw SIFT keypoint matches\n",
    "for m in good:\n",
    "    pt1 = (int(kp1[m.queryIdx].pt[0]), int(kp1[m.queryIdx].pt[1] + hdif))\n",
    "    pt2 = (int(kp2[m.trainIdx].pt[0] + w1), int(kp2[m.trainIdx].pt[1]))\n",
    "    cv2.line(newimg, pt1, pt2, (255, 0, 0))\n",
    "\n",
    "plt.imshow(newimg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to turn keypoints and descriptors into point cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from point_cloud import compute_essential_normalized, compute_P_from_essential, reconstruct_one_point, linear_triangulation\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.8 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "src_pts = np.asarray([kp1[m.queryIdx].pt for m in good])\n",
    "dst_pts = np.asarray([kp2[m.trainIdx].pt for m in good])\n",
    "\n",
    "retval, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 100.0)\n",
    "mask = mask.ravel()\n",
    "\n",
    "pts1 = src_pts[mask == 1]\n",
    "pts2 = dst_pts[mask == 1]\n",
    "\n",
    "height, width = img1.shape\n",
    "intrinsic = np.array([  # for dino\n",
    "    [2360, 0, width / 2],\n",
    "    [0, 2360, height / 2],\n",
    "    [0, 0, 1]])\n",
    "\n",
    "points1n = np.dot(np.linalg.inv(intrinsic), pts1.T)\n",
    "points2n = np.dot(np.linalg.inv(intrinsic), pts2.T)\n",
    "\n",
    "E = compute_essential_normalized(points1n, points2n)\n",
    "print('Computed essential matrix:', (-E / E[0][1]))\n",
    "\n",
    "\n",
    "P1 = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]])\n",
    "P2s = compute_P_from_essential(E)\n",
    "\n",
    "ind = -1\n",
    "for i, P2 in enumerate(P2s):\n",
    "    d1 = reconstruct_one_point(\n",
    "        points1n[:, 0], points2n[:, 0], P1, P2)\n",
    "\n",
    "    P2_homogenous = np.linalg.inv(np.vstack([P2, [0, 0, 0, 1]]))\n",
    "    d2 = np.dot(P2_homogenous[:3, :4], d1)\n",
    "\n",
    "    if d1[2] > 0 and d2[2] > 0:\n",
    "        ind = i\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "P2 = np.linalg.inv(np.vstack([P2s[ind], [0, 0, 0, 1]]))[:3, :4]\n",
    "tripoints3d = linear_triangulation(points1n, points2n, P1, P2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('3D reconstructed', fontsize=16)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(tripoints3d[0], tripoints3d[1], tripoints3d[2], 'b.')\n",
    "ax.set_xlabel('x axis')\n",
    "ax.set_ylabel('y axis')\n",
    "ax.set_zlabel('z axis')\n",
    "ax.view_init(elev=135, azim=90)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
