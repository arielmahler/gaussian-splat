{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the sift algorithm, with the trilinear interpolation smoothing of a histogram tensor of the generate descriptors being implemented in hardware using our overlay, histogram_tensor\n",
    "\n",
    "This overlay stream in inputs for the histogram tensor calculations, which are done on the board, and the resulting structure is stream back out and placed back into the software structure for further calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq import Overlay\n",
    "overlay = Overlay('/home/xilinx/pynq/overlays/descriptor/design_1.bit')\n",
    "dma = overlay.axi_dma_0\n",
    "# dma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfm_algo_unpacked import localizeExtremumViaQuadraticFit, computeKeypointsWithOrientations, isPixelAnExtremum\n",
    "from numpy import floor\n",
    "\n",
    "def findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width, contrast_threshold=0.04):\n",
    "    threshold = floor(0.5 * contrast_threshold / num_intervals * 255)\n",
    "    keypoints = []\n",
    "\n",
    "    for octave_index, dog_images_in_octave in enumerate(dog_images):\n",
    "        for image_index, (first_image, second_image, third_image) in enumerate(zip(dog_images_in_octave, dog_images_in_octave[1:], dog_images_in_octave[2:])):\n",
    "            for i in range(image_border_width, first_image.shape[0] - image_border_width):\n",
    "                if (i % 10 == 0):\n",
    "                    print('.', end='')\n",
    "                if (i % 100 == 0):\n",
    "                    print('')\n",
    "                for j in range(image_border_width, first_image.shape[1] - image_border_width):\n",
    "                    if isPixelAnExtremum(first_image[i-1:i+2, j-1:j+2], second_image[i-1:i+2, j-1:j+2], third_image[i-1:i+2, j-1:j+2], threshold):\n",
    "                        localization_result = localizeExtremumViaQuadraticFit(i, j, image_index + 1, octave_index, num_intervals, dog_images_in_octave, sigma, contrast_threshold, image_border_width)\n",
    "                        if localization_result is not None:\n",
    "                            keypoint, localized_image_index = localization_result\n",
    "                            keypoints_with_orientations = computeKeypointsWithOrientations(keypoint, octave_index, gaussian_images[octave_index][localized_image_index])\n",
    "                            for keypoint_with_orientation in keypoints_with_orientations:\n",
    "                                keypoints.append(keypoint_with_orientation)\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfm_algo_unpacked import generateBaseImage, computeNumberOfOctaves, generateGaussianKernels, generateGaussianImages, generateDoGImages, removeDuplicateKeypoints, convertKeypointsToInputImageSize, generateDescriptors, generateDescriptors_hardware\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "img1 = cv2.imread('dino_data/dino02.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('dino_data/dino05.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "sigma=1.6 \n",
    "num_intervals=3 \n",
    "assumed_blur=0.5 \n",
    "image_border_width=5\n",
    "\n",
    "base_image = generateBaseImage(img1, sigma, assumed_blur)\n",
    "print(\"Finished base_image\")\n",
    "num_octaves = computeNumberOfOctaves(base_image.shape)\n",
    "print(\"Finished num_octaves\")\n",
    "gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "print(\"Finished gaussian_kernels\")\n",
    "gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "print(\"Finished gaussian_images\")\n",
    "dog_images = generateDoGImages(gaussian_images)\n",
    "print(\"Finished dog_images\")\n",
    "keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "print(\"Finished keypoints\")\n",
    "keypoints = removeDuplicateKeypoints(keypoints)\n",
    "print(\"Finished remove duplicate keypoints\")\n",
    "kp1 = convertKeypointsToInputImageSize(keypoints)\n",
    "print(\"Finished convert to image size\")\n",
    "des1 = generateDescriptors_hardware(keypoints, gaussian_images, dma)\n",
    "print(\"Finished generate_descriptors\")\n",
    "\n",
    "base_image = generateBaseImage(img2, sigma, assumed_blur)\n",
    "print(\"Finished base_image\")\n",
    "num_octaves = computeNumberOfOctaves(base_image.shape)\n",
    "print(\"Finished num_octaves\")\n",
    "gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "print(\"Finished gaussian_kernels\")\n",
    "gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "print(\"Finished gaussian_images\")\n",
    "dog_images = generateDoGImages(gaussian_images)\n",
    "print(\"Finished dog_images\")\n",
    "keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "print(\"Finished keypoints\")\n",
    "keypoints = removeDuplicateKeypoints(keypoints)\n",
    "print(\"Finished remove duplicate keypoints\")\n",
    "kp2 = convertKeypointsToInputImageSize(keypoints)\n",
    "print(\"Finished convert to image size\")\n",
    "des2 = generateDescriptors_hardware(keypoints, gaussian_images, dma)\n",
    "print(\"Finished generate_descriptors\")\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Lowe's ratio test\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "\n",
    "# Estimate homography between template and scene\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "M = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)[0]\n",
    "\n",
    "# Draw detected template in scene image\n",
    "h, w = img1.shape\n",
    "pts = np.float32([[0, 0],\n",
    "                    [0, h - 1],\n",
    "                    [w - 1, h - 1],\n",
    "                    [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "dst = cv2.perspectiveTransform(pts, M)\n",
    "\n",
    "img2 = cv2.polylines(img2, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "\n",
    "h1, w1 = img1.shape\n",
    "h2, w2 = img2.shape\n",
    "nWidth = w1 + w2\n",
    "nHeight = max(h1, h2)\n",
    "hdif = int((h2 - h1) / 2)\n",
    "newimg = np.zeros((nHeight, nWidth, 3), np.uint8)\n",
    "\n",
    "for i in range(3):\n",
    "    newimg[hdif:hdif + h1, :w1, i] = img1\n",
    "    newimg[:h2, w1:w1 + w2, i] = img2\n",
    "\n",
    "# Draw SIFT keypoint matches\n",
    "for m in good:\n",
    "    pt1 = (int(kp1[m.queryIdx].pt[0]), int(kp1[m.queryIdx].pt[1] + hdif))\n",
    "    pt2 = (int(kp2[m.trainIdx].pt[0] + w1), int(kp2[m.trainIdx].pt[1]))\n",
    "    cv2.line(newimg, pt1, pt2, (255, 0, 0))\n",
    "\n",
    "plt.imshow(newimg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfm_algo_unpacked import generateBaseImage, computeNumberOfOctaves, generateGaussianKernels, generateGaussianImages, generateDoGImages, removeDuplicateKeypoints, convertKeypointsToInputImageSize, generateDescriptors, generateDescriptors_hardware\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "img1 = cv2.imread('dino_data/dino02.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "sigma=1.6 \n",
    "num_intervals=3 \n",
    "assumed_blur=0.5 \n",
    "image_border_width=5\n",
    "\n",
    "base_image = generateBaseImage(img1, sigma, assumed_blur)\n",
    "print(\"Finished base_image\")\n",
    "num_octaves = computeNumberOfOctaves(base_image.shape)\n",
    "print(\"Finished num_octaves\")\n",
    "gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "print(\"Finished gaussian_kernels\")\n",
    "gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "print(\"Finished gaussian_images\")\n",
    "dog_images = generateDoGImages(gaussian_images)\n",
    "print(\"Finished dog_images\")\n",
    "# keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "# print(\"Finished keypoints\")\n",
    "# keypoints = removeDuplicateKeypoints(keypoints)\n",
    "# print(\"Finished remove duplicate keypoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a KeyPoint into a Dictionary\n",
    "def convertKPToDict(KP):\n",
    "    return {\n",
    "        'angle': KP.angle,\n",
    "        'class_id': KP.class_id,\n",
    "        'octave': KP.octave,\n",
    "        'point': KP.pt,\n",
    "        'response': KP.response,\n",
    "        'size': KP.size\n",
    "    }\n",
    "\n",
    "def convertDictToKP(D):\n",
    "    return cv2.KeyPoint(*D['point'],\n",
    "                   D['size'],\n",
    "                   D['angle'],\n",
    "                   D['response'],\n",
    "                   D['octave'])\n",
    "\n",
    "def KeyPointsToJSON(KPs):\n",
    "    output_list = []\n",
    "    for KP in KPs:\n",
    "        output_list.append(convertKPToDict(KP))\n",
    "    return output_list\n",
    "\n",
    "def unpackOctave(keypoint):\n",
    "    \"\"\"Compute octave, layer, and scale from a keypoint\n",
    "    \"\"\"\n",
    "    octave = 5308915 & 255\n",
    "    layer = (5308915 >> 8) & 255\n",
    "    if octave >= 128:\n",
    "        octave = octave | -128\n",
    "    scale = 1 / np.float32(1 << octave) if octave >= 0 else np.float32(1 << -octave)\n",
    "    return octave, layer, scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfm_algo_unpacked import generateBaseImage, computeNumberOfOctaves, generateGaussianKernels, generateGaussianImages, generateDoGImages, removeDuplicateKeypoints, convertKeypointsToInputImageSize, generateDescriptors, generateDescriptors_hardware\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "\n",
    "print(\"Finished convert to image size\")\n",
    "keypoints_json = []\n",
    "with open('data.json', 'r') as f:\n",
    "    pre_keypoints_json = json.load(f)\n",
    "    for kp in pre_keypoints_json:\n",
    "        keypoints_json.append(convertDictToKP(kp))\n",
    "print(len(keypoints_json))\n",
    "print(len(gaussian_images))\n",
    "print(unpackOctave(2818547))\n",
    "# print(len(keypoints))\n",
    "# kp1 = convertKeypointsToInputImageSize(keypoints)\n",
    "des1 = generateDescriptors_hardware(keypoints_json, gaussian_images, dma)\n",
    "print(\"Finished generate_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.imread('dino_data/dino05.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "sigma=1.6 \n",
    "num_intervals=3 \n",
    "assumed_blur=0.5 \n",
    "image_border_width=5\n",
    "\n",
    "base_image = generateBaseImage(img1, sigma, assumed_blur)\n",
    "print(\"Finished base_image\")\n",
    "num_octaves = computeNumberOfOctaves(base_image.shape)\n",
    "print(\"Finished num_octaves\")\n",
    "gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "print(\"Finished gaussian_kernels\")\n",
    "gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "print(\"Finished gaussian_images\")\n",
    "dog_images = generateDoGImages(gaussian_images)\n",
    "print(\"Finished dog_images\")\n",
    "keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "print(\"Finished keypoints\")\n",
    "keypoints = removeDuplicateKeypoints(keypoints)\n",
    "print(\"Finished remove duplicate keypoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp2 = convertKeypointsToInputImageSize(keypoints)\n",
    "print(\"Finished convert to image size\")\n",
    "des2 = generateDescriptors_hardware(keypoints, gaussian_images, dma)\n",
    "print(\"Finished generate_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Lowe's ratio test\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "\n",
    "# Estimate homography between template and scene\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "M = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)[0]\n",
    "\n",
    "# Draw detected template in scene image\n",
    "h, w = img1.shape\n",
    "pts = np.float32([[0, 0],\n",
    "                    [0, h - 1],\n",
    "                    [w - 1, h - 1],\n",
    "                    [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "dst = cv2.perspectiveTransform(pts, M)\n",
    "\n",
    "img2 = cv2.polylines(img2, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "\n",
    "h1, w1 = img1.shape\n",
    "h2, w2 = img2.shape\n",
    "nWidth = w1 + w2\n",
    "nHeight = max(h1, h2)\n",
    "hdif = int((h2 - h1) / 2)\n",
    "newimg = np.zeros((nHeight, nWidth, 3), np.uint8)\n",
    "\n",
    "for i in range(3):\n",
    "    newimg[hdif:hdif + h1, :w1, i] = img1\n",
    "    newimg[:h2, w1:w1 + w2, i] = img2\n",
    "\n",
    "# Draw SIFT keypoint matches\n",
    "for m in good:\n",
    "    pt1 = (int(kp1[m.queryIdx].pt[0]), int(kp1[m.queryIdx].pt[1] + hdif))\n",
    "    pt2 = (int(kp2[m.trainIdx].pt[0] + w1), int(kp2[m.trainIdx].pt[1]))\n",
    "    cv2.line(newimg, pt1, pt2, (255, 0, 0))\n",
    "\n",
    "plt.imshow(newimg)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
