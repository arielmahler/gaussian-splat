{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the sift algorithm, with the trilinear interpolation smoothing of a histogram tensor of the generate descriptors being implemented in hardware using our overlay, histogram_tensor\n",
    "\n",
    "This overlay stream in inputs for the histogram tensor calculations, which are done on the board, and the resulting structure is stream back out and placed back into the software structure for further calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq import Overlay\n",
    "overlay = Overlay('/home/xilinx/pynq/overlays/descriptor/design_1.bit')\n",
    "dma = overlay.axi_dma_0\n",
    "dma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fxpmath'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msfm_algo_unpacked\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m generateBaseImage, computeNumberOfOctaves, generateGaussianKernels, generateGaussianImages, generateDoGImages, findScaleSpaceExtrema, removeDuplicateKeypoints, convertKeypointsToInputImageSize, generateDescriptors, generateDescriptors_hardware\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m/home/xilinx/jupyter_notebooks/sfm_algo_unpacked.py:9\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpynq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m allocate\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfxpmath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Fxp\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrig\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtype_casts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fp_to_float\n\u001b[1;32m     13\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fxpmath'"
     ]
    }
   ],
   "source": [
    "from sfm_algo_unpacked import generateBaseImage, computeNumberOfOctaves, generateGaussianKernels, generateGaussianImages, generateDoGImages, findScaleSpaceExtrema, removeDuplicateKeypoints, convertKeypointsToInputImageSize, generateDescriptors, generateDescriptors_hardware\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "img1 = cv2.imread('dino_data/dino02.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread('dino_data/dino05.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "sigma=1.6 \n",
    "num_intervals=3 \n",
    "assumed_blur=0.5 \n",
    "image_border_width=5\n",
    "\n",
    "base_image = generateBaseImage(img1, sigma, assumed_blur)\n",
    "num_octaves = computeNumberOfOctaves(base_image.shape)\n",
    "gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "dog_images = generateDoGImages(gaussian_images)\n",
    "keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "keypoints = removeDuplicateKeypoints(keypoints)\n",
    "kp1 = convertKeypointsToInputImageSize(keypoints)\n",
    "des1 = generateDescriptors_hardware(keypoints, gaussian_images, dma)\n",
    "\n",
    "base_image = generateBaseImage(img2, sigma, assumed_blur)\n",
    "num_octaves = computeNumberOfOctaves(base_image.shape)\n",
    "gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "dog_images = generateDoGImages(gaussian_images)\n",
    "keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "keypoints = removeDuplicateKeypoints(keypoints)\n",
    "kp2 = convertKeypointsToInputImageSize(keypoints)\n",
    "des2 = generateDescriptors_hardware(keypoints, gaussian_images, dma)\n",
    "\n",
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Lowe's ratio test\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "\n",
    "# Estimate homography between template and scene\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "M = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)[0]\n",
    "\n",
    "# Draw detected template in scene image\n",
    "h, w = img1.shape\n",
    "pts = np.float32([[0, 0],\n",
    "                    [0, h - 1],\n",
    "                    [w - 1, h - 1],\n",
    "                    [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "dst = cv2.perspectiveTransform(pts, M)\n",
    "\n",
    "img2 = cv2.polylines(img2, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "\n",
    "h1, w1 = img1.shape\n",
    "h2, w2 = img2.shape\n",
    "nWidth = w1 + w2\n",
    "nHeight = max(h1, h2)\n",
    "hdif = int((h2 - h1) / 2)\n",
    "newimg = np.zeros((nHeight, nWidth, 3), np.uint8)\n",
    "\n",
    "for i in range(3):\n",
    "    newimg[hdif:hdif + h1, :w1, i] = img1\n",
    "    newimg[:h2, w1:w1 + w2, i] = img2\n",
    "\n",
    "# Draw SIFT keypoint matches\n",
    "for m in good:\n",
    "    pt1 = (int(kp1[m.queryIdx].pt[0]), int(kp1[m.queryIdx].pt[1] + hdif))\n",
    "    pt2 = (int(kp2[m.trainIdx].pt[0] + w1), int(kp2[m.trainIdx].pt[1]))\n",
    "    cv2.line(newimg, pt1, pt2, (255, 0, 0))\n",
    "\n",
    "plt.imshow(newimg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
