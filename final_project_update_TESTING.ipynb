{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the sift algorithm, with the trilinear interpolation smoothing of a histogram tensor of the generate descriptors being implemented in hardware using our overlay, histogram_tensor\n",
    "\n",
    "This overlay stream in inputs for the histogram tensor calculations, which are done on the board, and the resulting structure is stream back out and placed back into the software structure for further calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pynq import Overlay\n",
    "overlay = Overlay('/home/xilinx/pynq/overlays/descriptor/design_1.bit')\n",
    "dma = overlay.axi_dma_0\n",
    "# dma?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a KeyPoint into a Dictionary\n",
    "def convertKPToDict(KP):\n",
    "    return {\n",
    "        'angle': KP.angle,\n",
    "        'class_id': KP.class_id,\n",
    "        'octave': KP.octave,\n",
    "        'point': KP.pt,\n",
    "        'response': KP.response,\n",
    "        'size': KP.size\n",
    "    }\n",
    "\n",
    "def convertDictToKP(D):\n",
    "    return cv2.KeyPoint(*D['point'],\n",
    "                   D['size'],\n",
    "                   D['angle'],\n",
    "                   D['response'],\n",
    "                   D['octave'],\n",
    "                   D['class_id'])\n",
    "\n",
    "def KeyPointsToJSON(KPs):\n",
    "    output_list = []\n",
    "    for KP in KPs:\n",
    "        output_list.append(convertKPToDict(KP))\n",
    "    return output_list\n",
    "\n",
    "def unpackOctave(keypoint):\n",
    "    \"\"\"Compute octave, layer, and scale from a keypoint\n",
    "    \"\"\"\n",
    "    octave = keypoint.octave & 255\n",
    "    layer = (keypoint.octave >> 8) & 255\n",
    "    if octave >= 128:\n",
    "        octave = octave | -128\n",
    "    scale = 1 / np.float32(1 << octave) if octave >= 0 else np.float32(1 << -octave)\n",
    "    return octave, layer, scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfm_algo_unpacked import unpackOctave\n",
    "from numpy import all, any, array, arctan2, cos, sin, exp, dot, log, logical_and, roll, sqrt, stack, trace, unravel_index, pi, deg2rad, rad2deg, where, zeros, floor, full, nan, isnan, round, float32\n",
    "from pynq import allocate\n",
    "\n",
    "def fpga_zip(row_array, col_array, mag_array, ori_array):\n",
    "    minimum = min([len(array) for array in [row_array, col_array, mag_array, ori_array]])\n",
    "    input_buf = []\n",
    "    for i in range(minimum):\n",
    "        #convert values to fixed point\n",
    "        row_bin_fixed = np.float16(row_array[i])\n",
    "        col_bin_fixed = np.float16(col_array[i])\n",
    "        magnitude_fixed = np.float16(mag_array[i])\n",
    "        orientation_bin_fixed = np.float16(ori_array[i])\n",
    "        in_val = [row_bin_fixed, col_bin_fixed, magnitude_fixed, orientation_bin_fixed]\n",
    "        input_buf.append(in_val)\n",
    "    return input_buf\n",
    "\n",
    "def generateDescriptors_hardware(keypoints, gaussian_images, dma, window_width=4, num_bins=8, scale_multiplier=3, descriptor_max_value=0.2):\n",
    "    \"\"\"Generate descriptors for each keypoint\n",
    "    \"\"\"\n",
    "    print(\"Generating descriptors\")\n",
    "    descriptors = []\n",
    "\n",
    "    for keypoint in keypoints:\n",
    "        octave, layer, scale = unpackOctave(keypoint)\n",
    "        gaussian_image = gaussian_images[octave + 1][layer]\n",
    "        num_rows, num_cols = gaussian_image.shape\n",
    "        point = round(scale * array(keypoint.pt)).astype('int')\n",
    "        bins_per_degree = num_bins / 360.\n",
    "        angle = 360. - keypoint.angle\n",
    "        cos_angle = cos(deg2rad(angle))\n",
    "        sin_angle = sin(deg2rad(angle))\n",
    "        weight_multiplier = -0.5 / ((0.5 * window_width) ** 2)\n",
    "        row_bin_list = []\n",
    "        col_bin_list = []\n",
    "        magnitude_list = []\n",
    "        orientation_bin_list = []\n",
    "        histogram_tensor = zeros((window_width + 2, window_width + 2, num_bins)).tolist()   # first two dimensions are increased by 2 to account for border effects\n",
    "\n",
    "        # Descriptor window size (described by half_width)\n",
    "        hist_width = scale_multiplier * 0.5 * scale * keypoint.size\n",
    "        half_width = int(round(hist_width * sqrt(2) * (window_width + 1) * 0.5))   # sqrt(2) corresponds to diagonal length of a pixel\n",
    "        half_width = int(min(half_width, sqrt(num_rows ** 2 + num_cols ** 2)))     # ensure half_width lies within image\n",
    "\n",
    "        for row in range(-half_width, half_width + 1):\n",
    "            for col in range(-half_width, half_width + 1):\n",
    "                row_rot = col * sin_angle + row * cos_angle\n",
    "                col_rot = col * cos_angle - row * sin_angle\n",
    "                row_bin = (row_rot / hist_width) + 0.5 * window_width - 0.5\n",
    "                col_bin = (col_rot / hist_width) + 0.5 * window_width - 0.5\n",
    "                if row_bin > -1 and row_bin < window_width and col_bin > -1 and col_bin < window_width:\n",
    "                    window_row = int(round(point[1] + row))\n",
    "                    window_col = int(round(point[0] + col))\n",
    "                    if window_row > 0 and window_row < num_rows - 1 and window_col > 0 and window_col < num_cols - 1:\n",
    "                        dx = gaussian_image[window_row, window_col + 1] - gaussian_image[window_row, window_col - 1]\n",
    "                        dy = gaussian_image[window_row - 1, window_col] - gaussian_image[window_row + 1, window_col]\n",
    "                        gradient_magnitude = sqrt(dx * dx + dy * dy)\n",
    "                        gradient_orientation = rad2deg(arctan2(dy, dx)) % 360\n",
    "                        weight = exp(weight_multiplier * ((row_rot / hist_width) ** 2 + (col_rot / hist_width) ** 2))\n",
    "                        row_bin_list.append(row_bin)\n",
    "                        col_bin_list.append(col_bin)\n",
    "                        magnitude_list.append(weight * gradient_magnitude)\n",
    "                        orientation_bin_list.append((gradient_orientation - angle) * bins_per_degree)\n",
    "        \n",
    "        # do trilenear interpolation using the fpga overlay\n",
    "        input_buf = fpga_zip(row_bin_list, col_bin_list, magnitude_list, orientation_bin_list)\n",
    "        if (len(input_buf) == 0):\n",
    "            print(\"Continuing\")\n",
    "            continue;\n",
    "        input_buffer = allocate(shape=(len(input_buf), 4), dtype=np.float16)\n",
    "        array_area = len(histogram_tensor) * len(histogram_tensor[0]) * len(histogram_tensor[0][0])\n",
    "        output_buffer = allocate(shape=(array_area,), dtype=float32)\n",
    "        print(input_buffer.physical_address)\n",
    "        print(output_buffer.physical_address)\n",
    "        input_buffer[:] = input_buf\n",
    "        dma.sendchannel.transfer(input_buffer)\n",
    "        dma.sendchannel.wait()\n",
    "        dma.recvchannel.transfer(output_buffer)\n",
    "        dma.recvchannel.wait()\n",
    "        descriptor_vector = fpga_unzip(output_buffer)\n",
    "        del output_buffer, input_buffer\n",
    "        \n",
    "        # Threshold and normalize descriptor_vector\n",
    "        threshold = norm(descriptor_vector) * descriptor_max_value\n",
    "        descriptor_vector[descriptor_vector > threshold] = threshold\n",
    "        descriptor_vector /= max(norm(descriptor_vector), float_tolerance)\n",
    "        # Multiply by 512, round, and saturate between 0 and 255 to convert from float32 to unsigned char (OpenCV convention)\n",
    "        descriptor_vector = round(512 * descriptor_vector)\n",
    "        descriptor_vector[descriptor_vector < 0] = 0\n",
    "        descriptor_vector[descriptor_vector > 255] = 255\n",
    "        descriptors.append(descriptor_vector)\n",
    "    return array(descriptors, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RegisterMap {\n",
       "  MM2S_DMACR = Register(RS=1, Reset=0, Keyhole=0, Cyclic_BD_Enable=0, IOC_IrqEn=0, Dly_IrqEn=0, Err_IrqEn=0, IRQThreshold=1, IRQDelay=0),\n",
       "  MM2S_DMASR = Register(Halted=0, Idle=0, SGIncld=0, DMAIntErr=0, DMASlvErr=0, DMADecErr=0, SGIntErr=0, SGSlvErr=0, SGDecErr=0, IOC_Irq=0, Dly_Irq=0, Err_Irq=0, IRQThresholdSts=0, IRQDelaySts=0),\n",
       "  MM2S_CURDESC = Register(Current_Descriptor_Pointer=0),\n",
       "  MM2S_CURDESC_MSB = Register(Current_Descriptor_Pointer=0),\n",
       "  MM2S_TAILDESC = Register(Tail_Descriptor_Pointer=0),\n",
       "  MM2S_TAILDESC_MSB = Register(Tail_Descriptor_Pointer=0),\n",
       "  MM2S_SA = Register(Source_Address=0),\n",
       "  MM2S_SA_MSB = Register(Source_Address=0),\n",
       "  MM2S_LENGTH = Register(Length=0),\n",
       "  SG_CTL = Register(SG_CACHE=0, SG_USER=0),\n",
       "  S2MM_DMACR = Register(RS=1, Reset=0, Keyhole=0, Cyclic_BD_Enable=0, IOC_IrqEn=0, Dly_IrqEn=0, Err_IrqEn=0, IRQThreshold=1, IRQDelay=0),\n",
       "  S2MM_DMASR = Register(Halted=0, Idle=0, SGIncld=0, DMAIntErr=0, DMASlvErr=0, DMADecErr=0, SGIntErr=0, SGSlvErr=0, SGDecErr=0, IOC_Irq=0, Dly_Irq=0, Err_Irq=0, IRQThresholdSts=0, IRQDelaySts=0),\n",
       "  S2MM_CURDESC = Register(Current_Descriptor_Pointer=0),\n",
       "  S2MM_CURDESC_MSB = Register(Current_Descriptor_Pointer=0),\n",
       "  S2MM_TAILDESC = Register(Tail_Descriptor_Pointer=0),\n",
       "  S2MM_TAILDESC_MSB = Register(Tail_Descriptor_Pointer=0),\n",
       "  S2MM_DA = Register(Destination_Address=0),\n",
       "  S2MM_DA_MSB = Register(Destination_Address=0),\n",
       "  S2MM_LENGTH = Register(Length=0)\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dma.register_map.S2MM_DMACR.RS = 1\n",
    "# dma.register_map.S2MM_DMACR.RS = 0\n",
    "# dma.register_map.S2MM_DMACR.Reset = 1\n",
    "dma.register_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished base_image\n",
      "Finished num_octaves\n",
      "Finished gaussian_kernels\n",
      "Finished gaussian_images\n",
      "Finished dog_images\n"
     ]
    }
   ],
   "source": [
    "from sfm_algo_unpacked import generateBaseImage, computeNumberOfOctaves, generateGaussianKernels, generateGaussianImages, generateDoGImages, removeDuplicateKeypoints, convertKeypointsToInputImageSize, generateDescriptors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import cv2\n",
    "\n",
    "img1 = cv2.imread('dino_data/dino02.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "sigma=1.6 \n",
    "num_intervals=3 \n",
    "assumed_blur=0.5 \n",
    "image_border_width=5\n",
    "\n",
    "base_image = generateBaseImage(img1, sigma, assumed_blur)\n",
    "print(\"Finished base_image\")\n",
    "num_octaves = computeNumberOfOctaves(base_image.shape)\n",
    "print(\"Finished num_octaves\")\n",
    "gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "print(\"Finished gaussian_kernels\")\n",
    "gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "print(\"Finished gaussian_images\")\n",
    "dog_images = generateDoGImages(gaussian_images)\n",
    "print(\"Finished dog_images\")\n",
    "# keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "# print(\"Finished keypoints\")\n",
    "# keypoints = removeDuplicateKeypoints(keypoints)\n",
    "# print(\"Finished remove duplicate keypoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished convert to image size\n",
      "Generating descriptors\n",
      "Continuing\n",
      "Continuing\n",
      "Continuing\n",
      "Continuing\n",
      "Continuing\n",
      "Continuing\n",
      "Continuing\n",
      "Continuing\n",
      "Continuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7656/77272442.py:55: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  dx = gaussian_image[window_row, window_col + 1] - gaussian_image[window_row, window_col - 1]\n",
      "/tmp/ipykernel_7656/77272442.py:57: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  gradient_magnitude = sqrt(dx * dx + dy * dy)\n",
      "/tmp/ipykernel_7656/77272442.py:56: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  dy = gaussian_image[window_row - 1, window_col] - gaussian_image[window_row + 1, window_col]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377798656\n",
      "377786368\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fpga_unzip' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m kp1 \u001b[38;5;241m=\u001b[39m convertKeypointsToInputImageSize(keypoints_json)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished convert to image size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m des1 \u001b[38;5;241m=\u001b[39m \u001b[43mgenerateDescriptors_hardware\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeypoints_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgaussian_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished generate_descriptors\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mgenerateDescriptors_hardware\u001b[0;34m(keypoints, gaussian_images, dma, window_width, num_bins, scale_multiplier, descriptor_max_value)\u001b[0m\n\u001b[1;32m     78\u001b[0m dma\u001b[38;5;241m.\u001b[39mrecvchannel\u001b[38;5;241m.\u001b[39mtransfer(output_buffer)\n\u001b[1;32m     79\u001b[0m dma\u001b[38;5;241m.\u001b[39mrecvchannel\u001b[38;5;241m.\u001b[39mwait()\n\u001b[0;32m---> 80\u001b[0m descriptor_vector \u001b[38;5;241m=\u001b[39m \u001b[43mfpga_unzip\u001b[49m(output_buffer)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m output_buffer, input_buffer\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# Threshold and normalize descriptor_vector\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fpga_unzip' is not defined"
     ]
    }
   ],
   "source": [
    "from sfm_algo_unpacked import generateBaseImage, computeNumberOfOctaves, generateGaussianKernels, generateGaussianImages, generateDoGImages, removeDuplicateKeypoints, convertKeypointsToInputImageSize, generateDescriptors\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import json\n",
    "import cv2\n",
    "\n",
    "\n",
    "keypoints_json = []\n",
    "with open('data.json', 'r') as f:\n",
    "    pck = json.load(f)\n",
    "    for k in pck:\n",
    "        keypoints_json.append(convertDictToKP(k))\n",
    "# with open('data.json', 'w') as f:\n",
    "#     json.dump(KeyPointsToJSON(keypoints), f)\n",
    "\n",
    "# print(keypoints_json[0].octave)\n",
    "# print(keypoints[0].octave)\n",
    "kp1 = convertKeypointsToInputImageSize(keypoints_json)\n",
    "print(\"Finished convert to image size\")\n",
    "des1 = generateDescriptors_hardware(keypoints_json, gaussian_images, dma)\n",
    "print(\"Finished generate_descriptors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Image Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 = cv2.imread('dino_data/dino05.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "sigma=1.6 \n",
    "num_intervals=3 \n",
    "assumed_blur=0.5 \n",
    "image_border_width=5\n",
    "\n",
    "base_image = generateBaseImage(img1, sigma, assumed_blur)\n",
    "print(\"Finished base_image\")\n",
    "num_octaves = computeNumberOfOctaves(base_image.shape)\n",
    "print(\"Finished num_octaves\")\n",
    "gaussian_kernels = generateGaussianKernels(sigma, num_intervals)\n",
    "print(\"Finished gaussian_kernels\")\n",
    "gaussian_images = generateGaussianImages(base_image, num_octaves, gaussian_kernels)\n",
    "print(\"Finished gaussian_images\")\n",
    "dog_images = generateDoGImages(gaussian_images)\n",
    "print(\"Finished dog_images\")\n",
    "keypoints = findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width)\n",
    "print(\"Finished keypoints\")\n",
    "keypoints = removeDuplicateKeypoints(keypoints)\n",
    "print(\"Finished remove duplicate keypoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp2 = convertKeypointsToInputImageSize(keypoints)\n",
    "print(\"Finished convert to image size\")\n",
    "des2 = generateDescriptors_hardware(keypoints, gaussian_images, dma)\n",
    "print(\"Finished generate_descriptors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLANN_INDEX_KDTREE = 0\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "matches = flann.knnMatch(des1, des2, k=2)\n",
    "\n",
    "# Lowe's ratio test\n",
    "good = []\n",
    "for m, n in matches:\n",
    "    if m.distance < 0.7 * n.distance:\n",
    "        good.append(m)\n",
    "\n",
    "\n",
    "# Estimate homography between template and scene\n",
    "src_pts = np.float32([ kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "\n",
    "M = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)[0]\n",
    "\n",
    "# Draw detected template in scene image\n",
    "h, w = img1.shape\n",
    "pts = np.float32([[0, 0],\n",
    "                    [0, h - 1],\n",
    "                    [w - 1, h - 1],\n",
    "                    [w - 1, 0]]).reshape(-1, 1, 2)\n",
    "dst = cv2.perspectiveTransform(pts, M)\n",
    "\n",
    "img2 = cv2.polylines(img2, [np.int32(dst)], True, 255, 3, cv2.LINE_AA)\n",
    "\n",
    "h1, w1 = img1.shape\n",
    "h2, w2 = img2.shape\n",
    "nWidth = w1 + w2\n",
    "nHeight = max(h1, h2)\n",
    "hdif = int((h2 - h1) / 2)\n",
    "newimg = np.zeros((nHeight, nWidth, 3), np.uint8)\n",
    "\n",
    "for i in range(3):\n",
    "    newimg[hdif:hdif + h1, :w1, i] = img1\n",
    "    newimg[:h2, w1:w1 + w2, i] = img2\n",
    "\n",
    "# Draw SIFT keypoint matches\n",
    "for m in good:\n",
    "    pt1 = (int(kp1[m.queryIdx].pt[0]), int(kp1[m.queryIdx].pt[1] + hdif))\n",
    "    pt2 = (int(kp2[m.trainIdx].pt[0] + w1), int(kp2[m.trainIdx].pt[1]))\n",
    "    cv2.line(newimg, pt1, pt2, (255, 0, 0))\n",
    "\n",
    "plt.imshow(newimg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sfm_algo_unpacked import localizeExtremumViaQuadraticFit, computeKeypointsWithOrientations, isPixelAnExtremum\n",
    "from numpy import floor\n",
    "\n",
    "def findScaleSpaceExtrema(gaussian_images, dog_images, num_intervals, sigma, image_border_width, contrast_threshold=0.04):\n",
    "    threshold = floor(0.5 * contrast_threshold / num_intervals * 255)\n",
    "    keypoints = []\n",
    "\n",
    "    for octave_index, dog_images_in_octave in enumerate(dog_images):\n",
    "        for image_index, (first_image, second_image, third_image) in enumerate(zip(dog_images_in_octave, dog_images_in_octave[1:], dog_images_in_octave[2:])):\n",
    "            for i in range(image_border_width, first_image.shape[0] - image_border_width):\n",
    "                if (i % 10 == 0):\n",
    "                    print('.', end='')\n",
    "                if (i % 100 == 0):\n",
    "                    print('')\n",
    "                for j in range(image_border_width, first_image.shape[1] - image_border_width):\n",
    "                    if isPixelAnExtremum(first_image[i-1:i+2, j-1:j+2], second_image[i-1:i+2, j-1:j+2], third_image[i-1:i+2, j-1:j+2], threshold):\n",
    "                        localization_result = localizeExtremumViaQuadraticFit(i, j, image_index + 1, octave_index, num_intervals, dog_images_in_octave, sigma, contrast_threshold, image_border_width)\n",
    "                        if localization_result is not None:\n",
    "                            keypoint, localized_image_index = localization_result\n",
    "                            keypoints_with_orientations = computeKeypointsWithOrientations(keypoint, octave_index, gaussian_images[octave_index][localized_image_index])\n",
    "                            for keypoint_with_orientation in keypoints_with_orientations:\n",
    "                                keypoints.append(keypoint_with_orientation)\n",
    "    return keypoints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
